



古典线性回归模型（Classical Linear Regression Model，CLRM）。 同时满足正态性假设的线性回归模型，称为经典正态线性回归模型（Classical Normal Linear Regression Model, CNLRM）。

## 一、假设

### （一）模型设定

1、线性假定（linearity）：

总体模型为：$Y_i=\beta_0+\beta_1X_{i1}+\beta_2X_{i2}+\cdots+\beta_kX_{ik}+\mu_i\ \left(i=1,\cdots,n\right)$  
若边际效应可变，可引入平方项（$X_{ik}^2$）、三次方项（$X_{ik}^3$）或交叉项（$X_{ik}X_{im}$）

2、选择了正确的变量



### （二）解释变量

1、样本方差趋于非零有限常数

$$
\sum_{i=1}^{n}\frac{\left(X_i-\bar{X}\right)^2}{n}\rightarrow Q (n\rightarrow \infin )
$$

2、$R\left(\bm{X}_{\bm{n}\times\left(\bm{k}+\bm{1}\right)}\right)=k+1$

（1）无完全多重共线性：矩阵$\bm{X}$列满秩（多元特有）

（2）样本观测值变异性：样本中的观测值不能完全相同，无自相关



### （三）随机干扰项

1、$E\left(\bm{\varepsilon}\middle|\bm{X}\right)=\bm{0}$

（1）条件0均值性：

$$
E\left(\varepsilon_i|X_1,X_2,\cdots,X_k\right)=0, i=1,2,\cdots,n
$$

（2）严格外生性（strict exogeneity） ：

$$
Cov\left(\bm{X_i},\varepsilon_i\right)=E(\bm{X_i}\varepsilon_{i})=0, i=1,2,\cdots,n
$$

解释变量与随机项不相关，$\bm{X}$同期外生（contemporaneously exogenous），$\bm{X}$与$\varepsilon$同期不相关（contemporaneously uncorrelated）。

2、球型扰动项（spherical disturbance）

$$
Var\left(\bm{\varepsilon}\middle|\bm{X} \right) 
=E\left( \bm{\varepsilon}\bm{\varepsilon}^\prime\middle|\bm{X} 	\right) 
=E\left( \begin{matrix} 
\varepsilon_1^2&\cdots&\varepsilon_1\varepsilon_n\\\vdots&\ddots&\vdots\\
\varepsilon_n\varepsilon_1&\cdots&\varepsilon_n\varepsilon_n\\ 
\end{matrix} \middle|\bm{X}\right) 		
=\left(\begin{matrix}
\sigma^2&\      &0     \\
\       &\ddots &\   \\
0       &\      &\sigma^2 \\
\end{matrix}\right)
=\sigma^2\bm{I_n}
$$

（1）条件同方差（conditional homoskedasticity）：

$$
Var\left(\varepsilon_i\middle| X_1,X_2,\cdots,X_k\right)=\sigma^2，i=1,2,\cdots,n
$$

（2）序列不相关：

$$
Cov\left (\varepsilon_i,\varepsilon_j\middle| X_1,X_2,\cdots,X_k\right)=0,i\neq j  i,j=1,2,\cdots,n
$$

（3）正态性：在采用OLS进行参数估计时，不需要正态性假设。在利用参数估计量进行统计推断时，需要假设随机项的概率分布。

$$
\bm{\varepsilon}|\bm{X}\sim N\left(\bm{0},\sigma^2\bm{I_n}\right)\\ 
\varepsilon_i|X_1,X_2,\cdots,X_k\sim N\left(0,\sigma^2\right)
$$

## 二、模型设计

### （一）总体回归模型（population regression model, PRM）

又称数据生成过程（data creating process, DGP）

$$
Y_{i} = E(Y|X_{i1},X_{i2},\cdots,X_{iK})+\varepsilon_{i}\\ 
=\beta_{0} + \beta_{1}X_{i1}+\beta_{2}X_{i2}+\cdots+\beta_{k}X_{ik}+\varepsilon_{i}, i=1,2,⋯,n\\ 
\\   
\bm{Y}=\bm{X\beta}+\bm{\varepsilon}
$$

其中
$\bm{Y}\equiv (Y_{1} Y_{2} \cdots  Y_{n})'$，
$\bm{X}\equiv (X_{1} X_{2} \cdots X_{k})'$，
$X_{i}\equiv (X_{i1} X_{i2} ⋯ X_{ik})'$，
$\bm{\beta}\equiv (\beta_{0} \beta_{1} \beta_{2} \cdots \beta_{k})'$，
$\varepsilon \equiv (\varepsilon_{1} \varepsilon_{2} \cdots \varepsilon_{n})'$。

1、$Y_i$：被解释变量（explained variable）/因变量（dependent variable）/响应变量（response variable），假设为随机的

2、确定性部分/系统性部分：

$E(Y|X_{i1},X_{i2},\cdots,X_{ik})$；系统性误差，不同水平之间的差异，所属总体的特征

（1）$X$：解释变量（explanatory variable，regressor）/自变量（independent variable）/协变量（covariate），非随机

（2）$\beta_j(j=1,2,⋯,k)$：偏回归系数（partial regression coefficient）

（3）控制变量：为了准确估计感兴趣参数而控制的解释变量（control variables）

3、随机部分/非系统型部分：

（1）$\varepsilon_i$ ：离差（deviation）/随机误差项（stochastic error）/随机扰动项/随机干扰项（stochastic disturbance）；随机误差，水平内部存在的差异，单个个体的个别特征

> 设置原因：  
> ① 原生：代表未知的影响因素；变量的内在随机性  
> ② 衍生（可避免）：代表残缺数据；代表数据观测误差；代表众多细小影响因素；代表模型设定误差


### （二）样本回归模型

$$
Y_i  ={\hat{Y}}_i+{\hat{\varepsilon}}_i \\ 
={\hat{\beta}}_0+{\hat{\beta}}_1X_{i1}+{\hat{\beta}}_2X_{i2}+\cdots+{\hat{\beta}}_kX_{ik}+{\hat{\varepsilon}}_i\ , i=1,2,\cdots,n \\  
\mathbf{Y}=\mathbf{X}\hat{\mathbf{\beta}}+\hat{\mathbf{\varepsilon}}
$$

${\hat{Y}}_i$：样本回归函数（sample regression function，SRF）

${\hat{\varepsilon}}_i$：（样本）残差项/剩余项（residual）

## 三、检验与评价

### （一）拟合优度检验

$$
TSS=ESS+RSS
$$

> 总离差平方和（Total Sum of Squares）：  
> $TSS=\sum_{i=1}^{n}y_i^2=\sum_{i=1}^{n}\left(Y_i-\bar{Y}\right)^2=SST$  
> 回归平方和（Explained Sum of Squares）： 回归方程能解释的，  
> $ESS=\sum_{i=1}^{n}{\hat{y}}_i^2=\sum_{i=1}^{n}\left({\hat{Y}}_i-\bar{Y}\right)^2=SSA$  
> 残差平方和（Residual Sum of Squares）： 回归方程不能解释的  
> $RSS=\sum_{i=1}^{n}{\hat{\varepsilon}}_i^2=\sum_{i=1}^{n}\left(Y_i-{\hat{Y}}_i\right)^2=SSE$


1、拟合优度/可决系数/判定系数：

$$
R^2=\frac{ESS}{TSS} 
=\frac{\sum_{i=1}^{n}\left({\hat{Y}}_i-\bar{Y}\right)^2}{\sum_{i=1}^{n}\left(Y_i-\bar{Y}\right)^2} 
=1-\frac{RSS}{TSS}
=1-\frac{\sum_{i=1}^{n}{\hat{\varepsilon}}_i^2}{\sum_{i=1}^{n}\left(Y_i-\bar{Y}\right)^2}，0≤R^2≤1 \\ 
R^2=\left[Corr\left(Y_i,{\hat{Y}}_i\right)\right]^2
$$

> 含义：模型能解释Y变异或波动的$R^2$  
> 如果增加解释变量，$R^2$往往增大（至少不变）

2、校正拟合优度（adjusted $R^2$）：

$$
{\bar{R}}^2 
=1-\frac{\sum_{i=1}^{n}{ε_i^2/(n-k-1)}}{\sum_{i=1}^{n}{(Y_i-\bar{Y})^2}/(n-1)} 
=1-(1-R^2)\frac{n-1}{n-k-1}，0≤R^2≤1
$$

### （二）显著性检验

1、$t$检验

变量回归系数的显著性检验（$n-k\geq 8$时较为稳定）

$$
H_0:\beta_j=0；H_1：β_j≠0（j=1,2,⋯,k）
$$

一元：

$$
β_1： 
t
=\frac{\hat{β}_1-β_1}{S_{\hat{β}_1}} 
=\frac{\hat{β}_1-β_1}{\sqrt{\frac{\hat{σ}^2}{\sum_{i=1}^{n}{x_i^2}}}}；
β_0： 
t
=\frac{\hat{β}_0-β_0}{S_{\hat{β}_0}} 
=\frac{\hat{β}_1-β_1}{\sqrt{\frac{\hat{σ}^2\sum_{i=1}^{n}{X_i^2}}{n \sum_{i=1}^{n}{x_i^2}}}}
$$

多元：

$$
t=\frac{\hat{β}_j-β_j}{S_{\hat{β}_j}} =\frac{\hat{β}_j-β_j}{\sqrt{c_{jj}\frac{\sum_{i=1}^{n}{\varepsilon_i^2}}{n -k-1}}} =\frac{\hat{β}_j-β_j}{\sqrt{c_{ij}\frac{\bm{\hat{\varepsilon}}' \bm{ \hat{\varepsilon}}}{n -k-1}}} \sim t(n-k-1)
$$

$c_{jj}$：$\left(\bm{X}^\prime\bm{X}\right)^{-1}$对角线上的第$j$个元素

若$\left|t\right|>t_\frac{a}{2}$，拒绝$H_0$

2、$F$检验

总体线性关系显著性（$n\geq 30$或至少$n\geq3\left(k+1\right)$基本要求）

$$
H_0:\beta_1=\beta_2=\cdots=\beta_k=0；H_1：β_{j}, j=1,2,⋯,k不全为零
$$

一元：t检验与F检验一致

多元：
$$
F=\frac{ESS/k}{RSS/(n-k-1)} = \frac{\sum_{i=1}^{n}{\hat{y}_i^2/k}}{\sum_{i=1}^{n}{\hat{\varepsilon}_i^2/(n-k-1)}}\sim F(k,n-k-1)
$$

若$F>F_\alpha$，拒绝$H_0$

$$
{\bar{R}}^2=1-\frac{n-1}{n-k-1+kF}，F=\frac{R^2/k}{(1-R^2)/(n-k-1)}
$$




